import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt
from torch.autograd import Variable
import copy
import time

device = "cuda" if torch.cuda.is_available() else "cpu"

# LeNet Model definition
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)
 
    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x,training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
        
# MNIST Test dataset and dataloader declaration
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([
            transforms.ToTensor(),
            ])),
        batch_size=1, shuffle=True)
        
   # Initialize the network
model = Net().to(device)
pretrained_model ='/kaggle/input/lenet-mnist-model/lenet_mnist_model.pth'
# Load the pretrained model
model.load_state_dict(torch.load(pretrained_model, map_location=device))
model.to(device)
model.eval()

#test the accuracy before attack
def test(model,data):
    correct =0
    total =0
    model.to(device)
    
    for img,label in data:
        img,label =img.to(device),label.to(device)
        out =model(img)
        _,pred =out.max(1)
        correct += torch.eq(pred,label).sum()
        total += len(label)
    print('Accuracy before attack:%.3f'%(correct/total))
    
test(model,test_loader)

# for FOGDM attack
def frac_pert(model,img,labels,alpha,targeted =False,kappa=10,c=4,num_iter=50):
    model.to(device)
    img =img.to(device)
    #target =torch.tensor(target).unsqueeze(0)
    
    w =torch.zeros_like(img,requires_grad=True).to(device)
    epsilon =1e-5
    w0 = img+ w
    w1 = w0 + 0.1
    w1.detach_()
    w1.requires_grad = True
    criterion = nn.CrossEntropyLoss()
    
    def f(x):

        outputs = model(x)
        one_hot_labels = torch.eye(len(outputs[0])).to(device)[labels]

        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)
        #j = torch.masked_select(outputs, one_hot_labels.byte())
        j = torch.masked_select(outputs, one_hot_labels.bool())
        
        # If targeted, optimize for making the other class most likely 
        if targeted :
            return torch.clamp(i-j, min=-kappa)
        
        # If untargeted, optimize for making the other class most likely 
        else :
            return torch.clamp(j-i, min=-kappa)
    
#     out =model(img)
#     _,pred = out.max(1)
#     one_hot_label =torch.eye(len(out[0])).to(device)[pred]
#     _,target =((1-one_hot_label)*out).max(1)
    
    for step in range(num_iter):
        
        a = (torch.tanh(w1)+1)/2
        delta = torch.abs(w1-w0) + epsilon
        loss1 = f(a)
        loss2 = nn.MSELoss(reduction='sum')(a,img)
        loss = loss2 + c*torch.sum(loss1)
        if w1.grad !=None:
            w1.grad.zero_()
        loss.backward()
        
        if step <2:
            thou =0.01
        else:
            thou =0.001
        
        w2 = w1 - thou * torch.mul(w1.grad,torch.pow(delta,1-alpha))
        w0 = w1
        w1 = w2
        w1.detach_()
        w1.requires_grad =True
         
        print('- Learning Progress : %2.2f %% '%((step+1)/num_iter*100), end='\r')
    adv = (torch.tanh(w1)+1)/2
    return adv
    
# for the cw attack
def cw_l2_attack(model, images, labels, targeted=False, c=4, kappa=10, max_iter=100, learning_rate=0.01):
    model.to(device)
    images = images.to(device)     
    labels = labels

    # Define f-function
    def f(x):

        outputs = model(x)
        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)

        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)
        j = torch.masked_select(outputs, one_hot_labels.bool())
        
        # If targeted, optimize for making the other class most likely 
        if targeted :
            return torch.clamp(i-j, min=-kappa)
        
        # If untargeted, optimize for making the other class most likely 
        else :
            return torch.clamp(j-i, min=-kappa)
    
    w = torch.zeros_like(images, requires_grad=True).to(device)
    optimizer = optim.Adam([w], lr=learning_rate)

    prev = 1e10
    
    for step in range(max_iter) :

        a = 1/2*(nn.Tanh()(w) + 1)

        loss1 = nn.MSELoss(reduction='sum')(a, images)
        loss2 = torch.sum(c*f(a))

        cost = loss1 + loss2

        optimizer.zero_grad()
        cost.backward()
        optimizer.step()

        # Early Stop when loss does not converge.
        if step % (max_iter//10) == 0 :
            if cost > prev :
                print('Attack Stopped due to CONVERGENCE....')
                return a
            prev = cost
        
        print('- Learning Progress : %2.2f %%  ' %((step+1)/max_iter*100), end='\r')

    attack_images = 1/2*(nn.Tanh()(w) + 1)

    return attack_images
    
  # for the deepfool attack
  def zero_gradients(x):
    if isinstance(x, torch.Tensor):
        if x.grad is not None:
            x.grad.detach_()
            x.grad.zero_()
    elif isinstance(x, collections.abc.Iterable):
        for elem in x:
            zero_gradients(elem)
def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=50):

    """
       :param image: Image of size HxWx3
       :param net: network (input: images, output: values of activation **BEFORE** softmax).
       :param num_classes: num_classes (limits the number of classes to test against, by default = 10)
       :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).
       （用作终止标准，以防止更新消失，update在这里用作名词)
       :param max_iter: maximum number of iterations for deepfool (default = 50)
       :return: minimal perturbation that fools the classifier, number of iterations that
       it required, new estimated_label and perturbed image。
    """
    is_cuda = torch.cuda.is_available()
    image =image.to(device)
    net.to(device)


     #f_image是model(image)生成的向量
    f_image = net.forward(Variable(image, requires_grad=True)).data.cpu().numpy().flatten()
    I = (np.array(f_image)).flatten().argsort()[::-1]  #按从大到小排列，得到排序后的索引

    I = I[0:num_classes]
    label = I[0]  #label还是索引值

    input_shape = image.detach().cpu().numpy().shape
    pert_image = copy.deepcopy(image)  #copy模块的deepcopy函数
    w = np.zeros(input_shape)
    r_tot = np.zeros(input_shape)

    loop_i = 0

    x = Variable(pert_image, requires_grad=True)  # x:torch.Size([1, 3, 224, 224])
    fs = net.forward(x)
    fs_list = [fs[0,I[k]] for k in range(num_classes)]
    k_i = label

    while k_i == label and loop_i < max_iter:

        pert = np.inf  #np.inf为无穷大,可以比较大小
        fs[0, I[0]].backward(retain_graph=True)
        grad_orig = x.grad.data.cpu().numpy().copy()

        for k in range(1, num_classes):  #算出最小的那个标签
            zero_gradients(x)

            fs[0, I[k]].backward(retain_graph=True)
            cur_grad = x.grad.data.cpu().numpy().copy()

            # set new w_k and new f_k
            w_k = cur_grad - grad_orig
            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()

            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())

            # determine which w_k to use
            if pert_k < pert:  #如果pert_k有界
                pert = pert_k  #pert是最小的那个
                w = w_k        #w是与pert_k对应的grad差

        # compute r_i and r_tot
        # Added 1e-4 for numerical stability
        r_i =  (pert+1e-4) * w / np.linalg.norm(w) 
        r_tot = np.float32(r_tot + r_i)

        if is_cuda:
            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()
        else:
            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)

        x = Variable(pert_image, requires_grad=True)
        fs = net.forward(x)
        k_i = np.argmax(fs.data.cpu().numpy().flatten())

        loop_i += 1

    r_tot = (1+overshoot)*r_tot

    return r_tot, loop_i, label, k_i, pert_image
    
   # for pgd attack
   def pgd_attack(model, images, labels, eps=0.3, alpha=2/255, iters=40) : #alpha设成42的时候，标签没变，
    images = images.to(device)
    labels = labels.to(device)
    loss = nn.CrossEntropyLoss()
    model.to(device)
    # 原图像
    ori_images = images.data

    for i in range(iters) :
        images.requires_grad = True
        outputs = model(images)

        model.zero_grad()
        cost = loss(outputs, labels).to(device)
        cost.backward()
        # 图像 + 梯度得到对抗样本
        adv_images = images + eps*images.grad.sign()
        # 限制扰动范围
        eta = torch.clamp(adv_images - ori_images, min=-alpha, max=alpha)
        # 进行下一轮对抗样本的生成。破坏之前的计算图
        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()

    return images
    
    # for gsdm attack
    def gs_attack(model,img,labels,c=3,num_iter=120):
    model.to(device)
    img =img.to(device)
    labels =labels.to(device)
    
    w =torch.zeros_like(img).to(device)
    w.requires_grad =True
    w = img + w
    w.detach_()
    w.requires_grad =True
    criterion = nn.CrossEntropyLoss()
      
    for step in range(num_iter):
        
        a = (torch.tanh(w)+1)/2
        out = model(a)
        
        loss1 = F.nll_loss(out,labels)
        loss2 = nn.MSELoss(reduction='sum')(a,img)
        loss = loss2 - c*loss1
        
        if w.grad !=None:
            w.grad.zero_()
        loss.backward()
        
        if step <7:
            thou =0.1
        else:
            thou =0.01
            
        
        w = w - thou * torch.sign(w.grad)
        w.detach_()
        w.requires_grad =True
         
        print('- Learning Progress : %2.2f %% '%((step+1)/num_iter*100), end='\r')
    adv = (torch.tanh(w)+1)/2
    return adv
