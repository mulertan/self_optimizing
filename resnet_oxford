%matplotlib inline
import os
import torch
from torch import nn
import torchvision
import random
from PIL import Image
import numpy as np
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import glob
from torch import optim
import time
from torch.autograd import Variable
import copy

root ='/kaggle/input/the-oxfordiiit-pet-dataset/images'
device ='cuda' if torch.cuda.is_available() else 'cpu'
print(device)

def get_img_path(root):
    path =glob.glob(os.path.join(root,'*.jpg'))
    return path

def label_set(root):
    ss = []
    path =get_img_path(root)
    
    for path in path:
        ss.append(path.split('_')[0].split('/')[-1])
    classes = sorted(set(ss),key=str.lower)
    label2idx = {}
    for i,cl in enumerate(classes):
        label2idx[cl] = i
    return label2idx,classes
    
    label2idx,classes =label_set(root)
    
    # construct the dataset
    class datasetPet(Dataset):
    def __init__(self,root,label2idx):
        super().__init__()
        self.root =root
        self.files = get_img_path(root)
        self.label2idx = label2idx
        
    def __getitem__(self,idx):
        path = self.files[idx]
        label = self.label2idx[path.split('_')[0].split('/')[-1]]
        img = Image.open(path)
        if img.mode != 'RGB':
            img = img.convert('RGB')
        img =transforms.Compose([
            transforms.Resize((299,299)),
            transforms.ToTensor()
        ])(img)
        return img,label
    
    def __len__(self):
        return len(self.files)
        
    data =datasetPet(root,label2idx)
    data_loader =DataLoader(data,batch_size=1,shuffle=True)
    
#randomly select the 100 images and labels for test dataset
img_datas =[]
cnt =0
for img,label in data_loader:
    if cnt<1000:
        img_datas.append((img,label))
        cnt +=1
    else:
        break
#download the model and modified the output layer as 35 categories     
model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1)
model.fc = nn.Linear(in_features=2048,out_features=35,bias=True)

# load fine tuned weights
paras = torch.load('/kaggle/input/model-02/restnet50_35classes_299.pkl',map_location=device)
model.load_state_dict(paras)

#test the accuracy before attack
correct =0
model.eval()
for img,label in img_datas:
    output =model(img)
    _,pred =output.max(1)
    if pred == label:
        correct +=1
print(correct/1000)  #准确率是1.0 

#cw-attack on the model
def cw_l2_attack(model, images, labels, targeted=False, c=4, kappa=0, max_iter=100, learning_rate=0.01):
    model.to(device)
    images = images.to(device)     
    labels = labels

    # Define f-function
    def f(x):

        outputs = model(x)
        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)

        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)
        j = torch.masked_select(outputs, one_hot_labels.bool())
        
        # If targeted, optimize for making the other class most likely 
        if targeted :
            return torch.clamp(i-j, min=-kappa)
        
        # If untargeted, optimize for making the other class most likely 
        else :
            return torch.clamp(j-i, min=-kappa)
    
    w = torch.zeros_like(images, requires_grad=True).to(device)
    optimizer = optim.Adam([w], lr=learning_rate)

    prev = 1e10
    
    for step in range(max_iter) :

        a = 1/2*(nn.Tanh()(w) + 1)

        loss1 = nn.MSELoss(reduction='sum')(a, images)
        loss2 = torch.sum(c*f(a))

        cost = loss1 + loss2

        optimizer.zero_grad()
        cost.backward()
        optimizer.step()

        # Early Stop when loss does not converge.
        if step % (max_iter//10) == 0 :
            if cost > prev :
                print('Attack Stopped due to CONVERGENCE....')
                return a
            prev = cost
        
        print('- Learning Progress : %2.2f %%  ' %((step+1)/max_iter*100), end='\r')

    attack_images = 1/2*(nn.Tanh()(w) + 1)

    return attack_images
    
#test cw attack
start = time.time()
for img,label in img_datas:
    img =img.to(device)
    adv =cw_l2_attack(model, img, label)
    out =model(adv)
    _,pred =out.max(1)
    if pred.cpu() == label:
        correct +=1
    er += torch.norm(adv-img)/torch.norm(img)
print('The accuracy after attack is :%.3f'%(correct/1000))
print('The related error is :%.3f'%(er.item()/100))
end = time.time()
interval = end-start
print('time passed:%.2f second.'%(end-start))

#Deepfool adversarial attacks
def zero_gradients(x):
    if isinstance(x, torch.Tensor):
        if x.grad is not None:
            x.grad.detach_()
            x.grad.zero_()
    elif isinstance(x, collections.abc.Iterable):
        for elem in x:
            zero_gradients(elem)
 def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=50):

    """
       :param image: Image of size HxWx3
       :param net: network (input: images, output: values of activation **BEFORE** softmax).
       :param num_classes: num_classes (limits the number of classes to test against, by default = 10)
       :param overshoot: used as a termination criterion to prevent vanishing updates (default = 0.02).
       （用作终止标准，以防止更新消失，update在这里用作名词)
       :param max_iter: maximum number of iterations for deepfool (default = 50)
       :return: minimal perturbation that fools the classifier, number of iterations that
       it required, new estimated_label and perturbed image。
    """
    is_cuda = torch.cuda.is_available()
    image =image.to(device)
    net.to(device)

     #f_image是model(image)生成的向量
    f_image = net.forward(Variable(image, requires_grad=True)).data.cpu().numpy().flatten()
    I = (np.array(f_image)).flatten().argsort()[::-1]  #按从大到小排列，得到排序后的索引

    I = I[0:num_classes]
    label = I[0]  #label还是索引值

    input_shape = image.cpu().numpy().shape
    pert_image = copy.deepcopy(image)  #copy模块的deepcopy函数
    w = np.zeros(input_shape)
    r_tot = np.zeros(input_shape)

    loop_i = 0

    x = Variable(pert_image, requires_grad=True)  # x:torch.Size([1, 3, 224, 224])
    fs = net.forward(x)
    fs_list = [fs[0,I[k]] for k in range(num_classes)]
    k_i = label

    while k_i == label and loop_i < max_iter:

        pert = np.inf  #np.inf为无穷大,可以比较大小
        fs[0, I[0]].backward(retain_graph=True)
        grad_orig = x.grad.data.cpu().numpy().copy()

        for k in range(1, num_classes):  #算出最小的那个标签
            zero_gradients(x)

            fs[0, I[k]].backward(retain_graph=True)
            cur_grad = x.grad.data.cpu().numpy().copy()

            # set new w_k and new f_k
            w_k = cur_grad - grad_orig
            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()

            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())

            # determine which w_k to use
            if pert_k < pert:  #如果pert_k有界
                pert = pert_k  #pert是最小的那个
                w = w_k        #w是与pert_k对应的grad差

        # compute r_i and r_tot
        # Added 1e-4 for numerical stability
        r_i =  (pert+1e-4) * w / np.linalg.norm(w) 
        r_tot = np.float32(r_tot + r_i)

        if is_cuda:
            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()
        else:
            pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)

        x = Variable(pert_image, requires_grad=True)
        fs = net.forward(x)
        k_i = np.argmax(fs.data.cpu().numpy().flatten())

        loop_i += 1

    r_tot = (1+overshoot)*r_tot

    return r_tot, loop_i, label, k_i, pert_image
    
  #PGD adversarial attacks
  def pgd_attack(model, images, labels, eps=0.3, alpha=2/255, iters=40) :
    images = images.to(device)
    labels = labels.to(device)
    loss = nn.CrossEntropyLoss()
    model.to(device)
    # 原图像
    ori_images = images.data

    for i in range(iters) :
        images.requires_grad = True
        outputs = model(images)

        model.zero_grad()
        cost = loss(outputs, labels).to(device)
        cost.backward()
        # 图像 + 梯度得到对抗样本
        adv_images = images + eps*images.grad.sign()
        # 限制扰动范围
        eta = torch.clamp(adv_images - ori_images, min=-alpha, max=alpha)
        # 进行下一轮对抗样本的生成。破坏之前的计算图
        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()

    return images
    
    #fractional gradient descent method attacks
    def frac_perturbation(model,img,alpha,c=4,num_iter=50):
    model.to(device)
    img =img.to(device)
    
    w =torch.zeros_like(img,requires_grad=True).to(device)
    epsilon =1e-5
    w0 = img+ w
    w1 = w0 + 0.01
    w1.detach_()
    w1.requires_grad = True
    criterion = nn.CrossEntropyLoss()
    
    out =model(img)
    _,pred = out.max(1)
    one_hot_label =torch.eye(len(out[0])).to(device)[pred]
    _,target =((1-one_hot_label)*out).max(1)
    
    for step in range(num_iter):
        
        a = (torch.tanh(w1)+1)/2
        delta = torch.abs(w1-w0) + epsilon
        out = model(a)
        loss1 = criterion(out,target)
        loss2 = nn.MSELoss(reduction='sum')(a,img)
        loss = loss2 + c*torch.sum(loss1)
        if w1.grad !=None:
            w1.grad.zero_()
        loss.backward()
        
        if step <5:
            thou =0.05
        else:
            thou =0.001
        
        w2 = w1 - thou * torch.mul(w1.grad,torch.pow(delta,1-alpha))
        w0 =w1
        w1 =w2
        w1.detach_()
        w1.requires_grad =True
         
        print('- Learning Progress : %2.2f %% '%((step+1)/num_iter*100), end='\r')
    adv = (torch.tanh(w1)+1)/2
    return adv
    
  # Gradient sign attack
  def gs_attack(model,img,labels,c=1,num_iter=20):
    model.to(device)
    img =img.to(device)
    
    w =torch.zeros_like(img).to(device)
    w.requires_grad =True
    w = img + w
    w.detach_()
    w.requires_grad =True
    criterion = nn.CrossEntropyLoss()

    out =model(img)
    num_class = len(out[0])
    
    one_hot_label =torch.eye(num_class)[labels].to(device)
    _,target =torch.max((1-one_hot_label)*out,dim=1)
      
    for step in range(num_iter):
        
        a = (torch.tanh(w)+1)/2
        out = model(a)
        
        loss1 = criterion(out,target)
        loss2 = nn.MSELoss(reduction='sum')(a,img)
        loss = loss2 + c*loss1
        
        if w.grad !=None:
            w.grad.zero_()
        loss.backward()
        
        if step <15:
            thou =0.05
        else:
            thou =0.001
            
        
        w = w - thou * torch.sign(w.grad)
        w.detach_()
        w.requires_grad =True
         
        print('- Learning Progress : %2.2f %% '%((step+1)/num_iter*100), end='\r')
    adv = (torch.tanh(w)+1)/2
    return adv
